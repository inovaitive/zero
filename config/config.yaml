# ZERO Voice Assistant Configuration
# This file is auto-generated from config.example.yaml
# Customize as needed for your setup

# ============================================
# General Settings
# ============================================
general:
  name: "ZERO"
  personality: "jarvis"  # jarvis, formal, friendly
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  language: "en-US"

# ============================================
# Wake Word Detection
# ============================================
wake_word:
  enabled: true
  keyword: "jarvis"  # Options: jarvis, computer, hey-zero (depends on pvporcupine models)
  sensitivity: 0.5  # 0.0 (less sensitive) to 1.0 (more sensitive)
  access_key: "${PICOVOICE_ACCESS_KEY}"  # Set in .env file

# ============================================
# Speech-to-Text (Deepgram)
# ============================================
stt:
  provider: "deepgram"
  api_key: "${DEEPGRAM_API_KEY}"  # Set in .env file
  model: "nova-2"  # nova-2 (fastest), whisper (most accurate)
  language: "en-US"
  smart_format: true
  punctuate: true
  profanity_filter: false
  timeout: 10  # seconds

# ============================================
# Text-to-Speech (Coqui TTS)
# ============================================
tts:
  provider: "coqui"
  model: "tts_models/en/ljspeech/vits"  # VITS is faster than Tacotron2 (OPTIMIZED)
  # Alternative models:
  # - tts_models/en/ljspeech/tacotron2-DDC (slower but higher quality)
  # - tts_models/en/vctk/vits (multiple speakers)
  vocoder: "vocoder_models/en/ljspeech/hifigan_v2"
  speed: 1.1  # Slightly faster speech for responsiveness
  use_cuda: false  # Set to true if GPU available
  cache_enabled: true
  cache_dir: "data/cache/tts"
  pre_cache_common: true  # Pre-cache common phrases on startup (OPTIMIZED)

# ============================================
# Natural Language Understanding
# ============================================
nlu:
  # Local classification (spaCy)
  local:
    enabled: true
    confidence_threshold: 0.7  # Lowered from 0.8 for fewer cloud calls (OPTIMIZED)
    spacy_model: "en_core_web_sm"

  # Cloud classification (OpenAI) - Async with timeout
  cloud:
    enabled: true  # Enable for better accuracy, but uses async mode (OPTIMIZED)
    provider: "openai"
    api_key: "${OPENAI_API_KEY}"  # Set in .env file
    model: "gpt-3.5-turbo"  # Faster than gpt-4 (OPTIMIZED)
    temperature: 0.3  # 0.0 (deterministic) to 1.0 (creative)
    max_tokens: 200  # Reduced from 500 for faster responses (OPTIMIZED)
    timeout: 2.0  # Max wait time for cloud result (OPTIMIZED)
    async_mode: true  # Run cloud in parallel with local (OPTIMIZED)

# ============================================
# Context Management
# ============================================
context:
  enabled: true
  max_history: 5  # Number of previous interactions to remember
  timeout: 300  # seconds (5 minutes)

# ============================================
# Skills Configuration
# ============================================
skills:
  # Weather Skill
  weather:
    enabled: true
    api_key: "${OPENWEATHERMAP_API_KEY}"  # Set in .env file
    default_location: "auto"  # auto, or "City, Country"
    units: "metric"  # metric (Celsius), imperial (Fahrenheit)
    cache_ttl: 300  # seconds (5 minutes)

  # Timer Skill
  timer:
    enabled: true
    max_concurrent: 10
    default_sound: "data/sounds/alarm.wav"
    persistence: true  # Save timers between restarts

  # App Control Skill
  app_control:
    enabled: true
    # Custom app aliases (add your frequently used apps)
    aliases:
      chrome: "Google Chrome"
      browser: "Google Chrome"
      code: "Visual Studio Code"
      vscode: "Visual Studio Code"
      editor: "Visual Studio Code"
      music: "Spotify"

  # Search Skill
  search:
    enabled: true
    default_engine: "google"  # google, duckduckgo, bing

  # Small Talk Skill
  small_talk:
    enabled: true
    use_gpt: true  # Use GPT for complex conversations
    personality_prompt: |
      You are ZERO, a personal AI assistant inspired by J.A.R.V.I.S. from Iron Man.
      You are calm, intelligent, and slightly formal. You address the user as "sir" or "madam".
      You are helpful and professional, with occasional dry humor when appropriate.
      Keep responses concise and to the point.

# ============================================
# User Interface
# ============================================
ui:
  # CLI Settings
  cli:
    enabled: true
    theme: "dark"  # dark, light
    show_debug: false
    show_logs: true

  # System Tray
  tray:
    enabled: true
    show_notifications: true
    minimize_to_tray: true

# ============================================
# Audio Settings
# ============================================
audio:
  input:
    device_index: null  # null for default, or specific device index
    sample_rate: 16000
    chunk_size: 512
    channels: 1

  output:
    device_index: null  # null for default
    sample_rate: 22050

# ============================================
# Response Caching (OPTIMIZED)
# ============================================
response_cache:
  enabled: true
  ttl: 3600  # Cache responses for 1 hour
  max_entries: 1000
  cache_dir: "data/cache/responses"

# ============================================
# Performance Settings
# ============================================
performance:
  max_latency: 3.0  # seconds (target)
  lazy_load_models: true
  use_threading: true
  max_workers: 4
  profiling_enabled: true  # Enable performance profiling (OPTIMIZED)

# ============================================
# Development Settings
# ============================================
development:
  debug_mode: false
  log_api_calls: false
  save_audio: false  # Save recorded audio for debugging
  mock_apis: false  # Use mock responses instead of real APIs
